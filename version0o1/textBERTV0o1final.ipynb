{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f560f230-bce3-4b73-974b-16aa3a88047c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing complete. Train, validation, and test sets created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Paths\n",
    "csv_path = \"C:/Users/Rifat/Music/dsv1text/transcriptions2.csv\"\n",
    "model_save_path = \"C:/Users/Rifat/Music/Models/ver0o1\"\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(csv_path)\n",
    "texts = data['text'].values\n",
    "labels = data['label'].values\n",
    "\n",
    "# Splitting the dataset into train, validation, and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(texts, labels, test_size=0.3, random_state=42)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "class SarcasmDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "\n",
    "train_dataset = SarcasmDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = SarcasmDataset(val_texts, val_labels, tokenizer)\n",
    "test_dataset = SarcasmDataset(test_texts, test_labels, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "print(\"Data preprocessing complete. Train, validation, and test sets created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4363a8a-02da-4d42-abff-b80b1c2c243a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Rifat\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/30\n",
      "Epoch 1 | Batch 0 | Loss: 0.7638\n",
      "Epoch 1 | Batch 10 | Loss: 0.5767\n",
      "Epoch 1 | Batch 20 | Loss: 0.6517\n",
      "Epoch 1 | Batch 30 | Loss: 0.4777\n",
      "Epoch 1 | Batch 40 | Loss: 0.6736\n",
      "Epoch 1 | Batch 50 | Loss: 0.7309\n",
      "Epoch 1 | Batch 60 | Loss: 0.8461\n",
      "Epoch 1 | Batch 70 | Loss: 0.5729\n",
      "Epoch 1 | Batch 80 | Loss: 0.5990\n",
      "Epoch 1 | Batch 90 | Loss: 0.7428\n",
      "Validation Loss: 0.6597 | Validation Accuracy: 0.6145\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch1_valacc0.6145_text.pth\n",
      "\n",
      "Epoch 2/30\n",
      "Epoch 2 | Batch 0 | Loss: 0.7467\n",
      "Epoch 2 | Batch 10 | Loss: 0.6773\n",
      "Epoch 2 | Batch 20 | Loss: 0.5767\n",
      "Epoch 2 | Batch 30 | Loss: 0.6770\n",
      "Epoch 2 | Batch 40 | Loss: 0.8822\n",
      "Epoch 2 | Batch 50 | Loss: 0.8185\n",
      "Epoch 2 | Batch 60 | Loss: 0.5822\n",
      "Epoch 2 | Batch 70 | Loss: 0.7067\n",
      "Epoch 2 | Batch 80 | Loss: 0.6599\n",
      "Epoch 2 | Batch 90 | Loss: 0.6941\n",
      "Validation Loss: 0.6345 | Validation Accuracy: 0.6747\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch2_valacc0.6747_text.pth\n",
      "\n",
      "Epoch 3/30\n",
      "Epoch 3 | Batch 0 | Loss: 0.4436\n",
      "Epoch 3 | Batch 10 | Loss: 0.3370\n",
      "Epoch 3 | Batch 20 | Loss: 0.2728\n",
      "Epoch 3 | Batch 30 | Loss: 0.5074\n",
      "Epoch 3 | Batch 40 | Loss: 0.3808\n",
      "Epoch 3 | Batch 50 | Loss: 0.2395\n",
      "Epoch 3 | Batch 60 | Loss: 0.2330\n",
      "Epoch 3 | Batch 70 | Loss: 0.7075\n",
      "Epoch 3 | Batch 80 | Loss: 0.4335\n",
      "Epoch 3 | Batch 90 | Loss: 0.3650\n",
      "Validation Loss: 0.8410 | Validation Accuracy: 0.5783\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch3_valacc0.5783_text.pth\n",
      "\n",
      "Epoch 4/30\n",
      "Epoch 4 | Batch 0 | Loss: 0.0877\n",
      "Epoch 4 | Batch 10 | Loss: 0.0996\n",
      "Epoch 4 | Batch 20 | Loss: 0.1490\n",
      "Epoch 4 | Batch 30 | Loss: 0.4826\n",
      "Epoch 4 | Batch 40 | Loss: 0.3914\n",
      "Epoch 4 | Batch 50 | Loss: 0.1461\n",
      "Epoch 4 | Batch 60 | Loss: 0.0956\n",
      "Epoch 4 | Batch 70 | Loss: 0.2314\n",
      "Epoch 4 | Batch 80 | Loss: 0.2639\n",
      "Epoch 4 | Batch 90 | Loss: 0.0587\n",
      "Validation Loss: 1.0380 | Validation Accuracy: 0.5663\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch4_valacc0.5663_text.pth\n",
      "\n",
      "Epoch 5/30\n",
      "Epoch 5 | Batch 0 | Loss: 0.0403\n",
      "Epoch 5 | Batch 10 | Loss: 0.0355\n",
      "Epoch 5 | Batch 20 | Loss: 0.1241\n",
      "Epoch 5 | Batch 30 | Loss: 0.3051\n",
      "Epoch 5 | Batch 40 | Loss: 0.3705\n",
      "Epoch 5 | Batch 50 | Loss: 0.1134\n",
      "Epoch 5 | Batch 60 | Loss: 0.1335\n",
      "Epoch 5 | Batch 70 | Loss: 0.3391\n",
      "Epoch 5 | Batch 80 | Loss: 0.0483\n",
      "Epoch 5 | Batch 90 | Loss: 0.5038\n",
      "Validation Loss: 1.0911 | Validation Accuracy: 0.5904\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch5_valacc0.5904_text.pth\n",
      "\n",
      "Epoch 6/30\n",
      "Epoch 6 | Batch 0 | Loss: 0.0529\n",
      "Epoch 6 | Batch 10 | Loss: 0.0417\n",
      "Epoch 6 | Batch 20 | Loss: 0.0294\n",
      "Epoch 6 | Batch 30 | Loss: 0.0199\n",
      "Epoch 6 | Batch 40 | Loss: 0.5041\n",
      "Epoch 6 | Batch 50 | Loss: 0.3403\n",
      "Epoch 6 | Batch 60 | Loss: 0.0238\n",
      "Epoch 6 | Batch 70 | Loss: 0.5333\n",
      "Epoch 6 | Batch 80 | Loss: 0.0192\n",
      "Epoch 6 | Batch 90 | Loss: 0.0212\n",
      "Validation Loss: 1.3279 | Validation Accuracy: 0.5542\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch6_valacc0.5542_text.pth\n",
      "\n",
      "Epoch 7/30\n",
      "Epoch 7 | Batch 0 | Loss: 0.0238\n",
      "Epoch 7 | Batch 10 | Loss: 0.0249\n",
      "Epoch 7 | Batch 20 | Loss: 0.0202\n",
      "Epoch 7 | Batch 30 | Loss: 0.0191\n",
      "Epoch 7 | Batch 40 | Loss: 0.0458\n",
      "Epoch 7 | Batch 50 | Loss: 0.0166\n",
      "Epoch 7 | Batch 60 | Loss: 0.1338\n",
      "Epoch 7 | Batch 70 | Loss: 0.0243\n",
      "Epoch 7 | Batch 80 | Loss: 0.0458\n",
      "Epoch 7 | Batch 90 | Loss: 0.0201\n",
      "Validation Loss: 1.1961 | Validation Accuracy: 0.5904\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch7_valacc0.5904_text.pth\n",
      "\n",
      "Epoch 8/30\n",
      "Epoch 8 | Batch 0 | Loss: 0.0727\n",
      "Epoch 8 | Batch 10 | Loss: 0.0441\n",
      "Epoch 8 | Batch 20 | Loss: 0.0214\n",
      "Epoch 8 | Batch 30 | Loss: 0.6121\n",
      "Epoch 8 | Batch 40 | Loss: 0.1929\n",
      "Epoch 8 | Batch 50 | Loss: 0.2088\n",
      "Epoch 8 | Batch 60 | Loss: 0.3341\n",
      "Epoch 8 | Batch 70 | Loss: 0.0176\n",
      "Epoch 8 | Batch 80 | Loss: 0.0283\n",
      "Epoch 8 | Batch 90 | Loss: 0.0112\n",
      "Validation Loss: 1.6047 | Validation Accuracy: 0.5301\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch8_valacc0.5301_text.pth\n",
      "\n",
      "Epoch 9/30\n",
      "Epoch 9 | Batch 0 | Loss: 0.0184\n",
      "Epoch 9 | Batch 10 | Loss: 0.0082\n",
      "Epoch 9 | Batch 20 | Loss: 0.0075\n",
      "Epoch 9 | Batch 30 | Loss: 0.0098\n",
      "Epoch 9 | Batch 40 | Loss: 0.1322\n",
      "Epoch 9 | Batch 50 | Loss: 0.0096\n",
      "Epoch 9 | Batch 60 | Loss: 0.3398\n",
      "Epoch 9 | Batch 70 | Loss: 0.0936\n",
      "Epoch 9 | Batch 80 | Loss: 0.1365\n",
      "Epoch 9 | Batch 90 | Loss: 0.0101\n",
      "Validation Loss: 1.6047 | Validation Accuracy: 0.5422\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch9_valacc0.5422_text.pth\n",
      "\n",
      "Epoch 10/30\n",
      "Epoch 10 | Batch 0 | Loss: 0.0116\n",
      "Epoch 10 | Batch 10 | Loss: 0.2215\n",
      "Epoch 10 | Batch 20 | Loss: 0.0074\n",
      "Epoch 10 | Batch 30 | Loss: 0.0830\n",
      "Epoch 10 | Batch 40 | Loss: 0.0042\n",
      "Epoch 10 | Batch 50 | Loss: 0.0055\n",
      "Epoch 10 | Batch 60 | Loss: 0.0024\n",
      "Epoch 10 | Batch 70 | Loss: 0.1921\n",
      "Epoch 10 | Batch 80 | Loss: 0.0825\n",
      "Epoch 10 | Batch 90 | Loss: 0.0090\n",
      "Validation Loss: 1.7563 | Validation Accuracy: 0.6084\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch10_valacc0.6084_text.pth\n",
      "\n",
      "Epoch 11/30\n",
      "Epoch 11 | Batch 0 | Loss: 0.1001\n",
      "Epoch 11 | Batch 10 | Loss: 0.0051\n",
      "Epoch 11 | Batch 20 | Loss: 0.0026\n",
      "Epoch 11 | Batch 30 | Loss: 0.0038\n",
      "Epoch 11 | Batch 40 | Loss: 0.1565\n",
      "Epoch 11 | Batch 50 | Loss: 0.0858\n",
      "Epoch 11 | Batch 60 | Loss: 0.0041\n",
      "Epoch 11 | Batch 70 | Loss: 0.0038\n",
      "Epoch 11 | Batch 80 | Loss: 0.0042\n",
      "Epoch 11 | Batch 90 | Loss: 0.0028\n",
      "Validation Loss: 1.8787 | Validation Accuracy: 0.5964\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch11_valacc0.5964_text.pth\n",
      "\n",
      "Epoch 12/30\n",
      "Epoch 12 | Batch 0 | Loss: 0.0020\n",
      "Epoch 12 | Batch 10 | Loss: 0.0025\n",
      "Epoch 12 | Batch 20 | Loss: 0.0667\n",
      "Epoch 12 | Batch 30 | Loss: 0.0690\n",
      "Epoch 12 | Batch 40 | Loss: 0.0017\n",
      "Epoch 12 | Batch 50 | Loss: 0.0019\n",
      "Epoch 12 | Batch 60 | Loss: 0.1354\n",
      "Epoch 12 | Batch 70 | Loss: 0.0896\n",
      "Epoch 12 | Batch 80 | Loss: 0.0536\n",
      "Epoch 12 | Batch 90 | Loss: 0.0931\n",
      "Validation Loss: 1.7994 | Validation Accuracy: 0.5542\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch12_valacc0.5542_text.pth\n",
      "\n",
      "Epoch 13/30\n",
      "Epoch 13 | Batch 0 | Loss: 0.0055\n",
      "Epoch 13 | Batch 10 | Loss: 0.0022\n",
      "Epoch 13 | Batch 20 | Loss: 0.0814\n",
      "Epoch 13 | Batch 30 | Loss: 0.0023\n",
      "Epoch 13 | Batch 40 | Loss: 0.0778\n",
      "Epoch 13 | Batch 50 | Loss: 0.0015\n",
      "Epoch 13 | Batch 60 | Loss: 0.0054\n",
      "Epoch 13 | Batch 70 | Loss: 0.0021\n",
      "Epoch 13 | Batch 80 | Loss: 0.0013\n",
      "Epoch 13 | Batch 90 | Loss: 0.1248\n",
      "Validation Loss: 2.3130 | Validation Accuracy: 0.5120\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch13_valacc0.5120_text.pth\n",
      "\n",
      "Epoch 14/30\n",
      "Epoch 14 | Batch 0 | Loss: 0.3604\n",
      "Epoch 14 | Batch 10 | Loss: 0.1266\n",
      "Epoch 14 | Batch 20 | Loss: 0.0634\n",
      "Epoch 14 | Batch 30 | Loss: 0.2026\n",
      "Epoch 14 | Batch 40 | Loss: 0.2136\n",
      "Epoch 14 | Batch 50 | Loss: 0.1178\n",
      "Epoch 14 | Batch 60 | Loss: 0.0950\n",
      "Epoch 14 | Batch 70 | Loss: 0.1167\n",
      "Epoch 14 | Batch 80 | Loss: 0.1064\n",
      "Epoch 14 | Batch 90 | Loss: 0.0937\n",
      "Validation Loss: 1.7030 | Validation Accuracy: 0.5904\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch14_valacc0.5904_text.pth\n",
      "\n",
      "Epoch 15/30\n",
      "Epoch 15 | Batch 0 | Loss: 0.0656\n",
      "Epoch 15 | Batch 10 | Loss: 0.1365\n",
      "Epoch 15 | Batch 20 | Loss: 0.0732\n",
      "Epoch 15 | Batch 30 | Loss: 0.1094\n",
      "Epoch 15 | Batch 40 | Loss: 0.0709\n",
      "Epoch 15 | Batch 50 | Loss: 0.0155\n",
      "Epoch 15 | Batch 60 | Loss: 0.0653\n",
      "Epoch 15 | Batch 70 | Loss: 0.0560\n",
      "Epoch 15 | Batch 80 | Loss: 0.0026\n",
      "Epoch 15 | Batch 90 | Loss: 0.1189\n",
      "Validation Loss: 1.8241 | Validation Accuracy: 0.5783\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch15_valacc0.5783_text.pth\n",
      "\n",
      "Epoch 16/30\n",
      "Epoch 16 | Batch 0 | Loss: 0.0272\n",
      "Epoch 16 | Batch 10 | Loss: 0.2073\n",
      "Epoch 16 | Batch 20 | Loss: 0.0897\n",
      "Epoch 16 | Batch 30 | Loss: 0.0033\n",
      "Epoch 16 | Batch 40 | Loss: 0.0045\n",
      "Epoch 16 | Batch 50 | Loss: 0.0041\n",
      "Epoch 16 | Batch 60 | Loss: 0.1657\n",
      "Epoch 16 | Batch 70 | Loss: 0.0034\n",
      "Epoch 16 | Batch 80 | Loss: 0.0017\n",
      "Epoch 16 | Batch 90 | Loss: 0.1024\n",
      "Validation Loss: 1.8819 | Validation Accuracy: 0.5542\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch16_valacc0.5542_text.pth\n",
      "\n",
      "Epoch 17/30\n",
      "Epoch 17 | Batch 0 | Loss: 0.0062\n",
      "Epoch 17 | Batch 10 | Loss: 0.0040\n",
      "Epoch 17 | Batch 20 | Loss: 0.0030\n",
      "Epoch 17 | Batch 30 | Loss: 0.1161\n",
      "Epoch 17 | Batch 40 | Loss: 0.1171\n",
      "Epoch 17 | Batch 50 | Loss: 0.0075\n",
      "Epoch 17 | Batch 60 | Loss: 0.0879\n",
      "Epoch 17 | Batch 70 | Loss: 0.0026\n",
      "Epoch 17 | Batch 80 | Loss: 0.1028\n",
      "Epoch 17 | Batch 90 | Loss: 0.1360\n",
      "Validation Loss: 2.0802 | Validation Accuracy: 0.5542\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch17_valacc0.5542_text.pth\n",
      "\n",
      "Epoch 18/30\n",
      "Epoch 18 | Batch 0 | Loss: 0.0926\n",
      "Epoch 18 | Batch 10 | Loss: 0.0013\n",
      "Epoch 18 | Batch 20 | Loss: 0.0021\n",
      "Epoch 18 | Batch 30 | Loss: 0.0018\n",
      "Epoch 18 | Batch 40 | Loss: 0.1856\n",
      "Epoch 18 | Batch 50 | Loss: 0.0013\n",
      "Epoch 18 | Batch 60 | Loss: 0.0027\n",
      "Epoch 18 | Batch 70 | Loss: 0.0018\n",
      "Epoch 18 | Batch 80 | Loss: 0.0373\n",
      "Epoch 18 | Batch 90 | Loss: 0.0022\n",
      "Validation Loss: 1.9088 | Validation Accuracy: 0.5783\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch18_valacc0.5783_text.pth\n",
      "\n",
      "Epoch 19/30\n",
      "Epoch 19 | Batch 0 | Loss: 0.0741\n",
      "Epoch 19 | Batch 10 | Loss: 0.1092\n",
      "Epoch 19 | Batch 20 | Loss: 0.0016\n",
      "Epoch 19 | Batch 30 | Loss: 0.0017\n",
      "Epoch 19 | Batch 40 | Loss: 0.0016\n",
      "Epoch 19 | Batch 50 | Loss: 0.0918\n",
      "Epoch 19 | Batch 60 | Loss: 0.0067\n",
      "Epoch 19 | Batch 70 | Loss: 0.0850\n",
      "Epoch 19 | Batch 80 | Loss: 0.1847\n",
      "Epoch 19 | Batch 90 | Loss: 0.1161\n",
      "Validation Loss: 1.9040 | Validation Accuracy: 0.5542\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch19_valacc0.5542_text.pth\n",
      "\n",
      "Epoch 20/30\n",
      "Epoch 20 | Batch 0 | Loss: 0.0019\n",
      "Epoch 20 | Batch 10 | Loss: 0.0021\n",
      "Epoch 20 | Batch 20 | Loss: 0.0049\n",
      "Epoch 20 | Batch 30 | Loss: 0.0018\n",
      "Epoch 20 | Batch 40 | Loss: 0.0019\n",
      "Epoch 20 | Batch 50 | Loss: 0.2343\n",
      "Epoch 20 | Batch 60 | Loss: 0.0677\n",
      "Epoch 20 | Batch 70 | Loss: 0.0012\n",
      "Epoch 20 | Batch 80 | Loss: 0.1311\n",
      "Epoch 20 | Batch 90 | Loss: 0.0924\n",
      "Validation Loss: 1.8641 | Validation Accuracy: 0.5843\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch20_valacc0.5843_text.pth\n",
      "\n",
      "Epoch 21/30\n",
      "Epoch 21 | Batch 0 | Loss: 0.0071\n",
      "Epoch 21 | Batch 10 | Loss: 0.0027\n",
      "Epoch 21 | Batch 20 | Loss: 0.0021\n",
      "Epoch 21 | Batch 30 | Loss: 0.0017\n",
      "Epoch 21 | Batch 40 | Loss: 0.0974\n",
      "Epoch 21 | Batch 50 | Loss: 0.0014\n",
      "Epoch 21 | Batch 60 | Loss: 0.0082\n",
      "Epoch 21 | Batch 70 | Loss: 0.0017\n",
      "Epoch 21 | Batch 80 | Loss: 0.0018\n",
      "Epoch 21 | Batch 90 | Loss: 0.0941\n",
      "Validation Loss: 2.1004 | Validation Accuracy: 0.5723\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch21_valacc0.5723_text.pth\n",
      "\n",
      "Epoch 22/30\n",
      "Epoch 22 | Batch 0 | Loss: 0.0009\n",
      "Epoch 22 | Batch 10 | Loss: 0.0909\n",
      "Epoch 22 | Batch 20 | Loss: 0.0009\n",
      "Epoch 22 | Batch 30 | Loss: 0.0775\n",
      "Epoch 22 | Batch 40 | Loss: 0.0018\n",
      "Epoch 22 | Batch 50 | Loss: 0.0871\n",
      "Epoch 22 | Batch 60 | Loss: 0.0007\n",
      "Epoch 22 | Batch 70 | Loss: 0.0019\n",
      "Epoch 22 | Batch 80 | Loss: 0.0013\n",
      "Epoch 22 | Batch 90 | Loss: 0.0960\n",
      "Validation Loss: 2.1455 | Validation Accuracy: 0.5723\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch22_valacc0.5723_text.pth\n",
      "\n",
      "Epoch 23/30\n",
      "Epoch 23 | Batch 0 | Loss: 0.0010\n",
      "Epoch 23 | Batch 10 | Loss: 0.0710\n",
      "Epoch 23 | Batch 20 | Loss: 0.0821\n",
      "Epoch 23 | Batch 30 | Loss: 0.0015\n",
      "Epoch 23 | Batch 40 | Loss: 0.0892\n",
      "Epoch 23 | Batch 50 | Loss: 0.0009\n",
      "Epoch 23 | Batch 60 | Loss: 0.1320\n",
      "Epoch 23 | Batch 70 | Loss: 0.0005\n",
      "Epoch 23 | Batch 80 | Loss: 0.0007\n",
      "Epoch 23 | Batch 90 | Loss: 0.0925\n",
      "Validation Loss: 2.3588 | Validation Accuracy: 0.5542\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch23_valacc0.5542_text.pth\n",
      "\n",
      "Epoch 24/30\n",
      "Epoch 24 | Batch 0 | Loss: 0.0666\n",
      "Epoch 24 | Batch 10 | Loss: 0.0009\n",
      "Epoch 24 | Batch 20 | Loss: 0.0007\n",
      "Epoch 24 | Batch 30 | Loss: 0.1317\n",
      "Epoch 24 | Batch 40 | Loss: 0.0017\n",
      "Epoch 24 | Batch 50 | Loss: 0.0993\n",
      "Epoch 24 | Batch 60 | Loss: 0.0799\n",
      "Epoch 24 | Batch 70 | Loss: 0.1362\n",
      "Epoch 24 | Batch 80 | Loss: 0.1006\n",
      "Epoch 24 | Batch 90 | Loss: 0.1186\n",
      "Validation Loss: 2.2122 | Validation Accuracy: 0.5783\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch24_valacc0.5783_text.pth\n",
      "\n",
      "Epoch 25/30\n",
      "Epoch 25 | Batch 0 | Loss: 0.0008\n",
      "Epoch 25 | Batch 10 | Loss: 0.0007\n",
      "Epoch 25 | Batch 20 | Loss: 0.0007\n",
      "Epoch 25 | Batch 30 | Loss: 0.0006\n",
      "Epoch 25 | Batch 40 | Loss: 0.0873\n",
      "Epoch 25 | Batch 50 | Loss: 0.0012\n",
      "Epoch 25 | Batch 60 | Loss: 0.1055\n",
      "Epoch 25 | Batch 70 | Loss: 0.0006\n",
      "Epoch 25 | Batch 80 | Loss: 0.0007\n",
      "Epoch 25 | Batch 90 | Loss: 0.1835\n",
      "Validation Loss: 2.2531 | Validation Accuracy: 0.5843\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch25_valacc0.5843_text.pth\n",
      "\n",
      "Epoch 26/30\n",
      "Epoch 26 | Batch 0 | Loss: 0.0012\n",
      "Epoch 26 | Batch 10 | Loss: 0.0004\n",
      "Epoch 26 | Batch 20 | Loss: 0.0004\n",
      "Epoch 26 | Batch 30 | Loss: 0.0011\n",
      "Epoch 26 | Batch 40 | Loss: 0.0003\n",
      "Epoch 26 | Batch 50 | Loss: 0.0025\n",
      "Epoch 26 | Batch 60 | Loss: 0.0004\n",
      "Epoch 26 | Batch 70 | Loss: 0.0913\n",
      "Epoch 26 | Batch 80 | Loss: 0.0006\n",
      "Epoch 26 | Batch 90 | Loss: 0.1829\n",
      "Validation Loss: 2.2717 | Validation Accuracy: 0.5904\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch26_valacc0.5904_text.pth\n",
      "\n",
      "Epoch 27/30\n",
      "Epoch 27 | Batch 0 | Loss: 0.0007\n",
      "Epoch 27 | Batch 10 | Loss: 0.0006\n",
      "Epoch 27 | Batch 20 | Loss: 0.0006\n",
      "Epoch 27 | Batch 30 | Loss: 0.0004\n",
      "Epoch 27 | Batch 40 | Loss: 0.0005\n",
      "Epoch 27 | Batch 50 | Loss: 0.0005\n",
      "Epoch 27 | Batch 60 | Loss: 0.0004\n",
      "Epoch 27 | Batch 70 | Loss: 0.0014\n",
      "Epoch 27 | Batch 80 | Loss: 0.0006\n",
      "Epoch 27 | Batch 90 | Loss: 0.0004\n",
      "Validation Loss: 2.2910 | Validation Accuracy: 0.5843\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch27_valacc0.5843_text.pth\n",
      "\n",
      "Epoch 28/30\n",
      "Epoch 28 | Batch 0 | Loss: 0.0835\n",
      "Epoch 28 | Batch 10 | Loss: 0.0005\n",
      "Epoch 28 | Batch 20 | Loss: 0.0006\n",
      "Epoch 28 | Batch 30 | Loss: 0.1020\n",
      "Epoch 28 | Batch 40 | Loss: 0.0006\n",
      "Epoch 28 | Batch 50 | Loss: 0.0930\n",
      "Epoch 28 | Batch 60 | Loss: 0.0003\n",
      "Epoch 28 | Batch 70 | Loss: 0.0005\n",
      "Epoch 28 | Batch 80 | Loss: 0.1054\n",
      "Epoch 28 | Batch 90 | Loss: 0.1186\n",
      "Validation Loss: 2.3416 | Validation Accuracy: 0.5843\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch28_valacc0.5843_text.pth\n",
      "\n",
      "Epoch 29/30\n",
      "Epoch 29 | Batch 0 | Loss: 0.0005\n",
      "Epoch 29 | Batch 10 | Loss: 0.0004\n",
      "Epoch 29 | Batch 20 | Loss: 0.0004\n",
      "Epoch 29 | Batch 30 | Loss: 0.1626\n",
      "Epoch 29 | Batch 40 | Loss: 0.0004\n",
      "Epoch 29 | Batch 50 | Loss: 0.0007\n",
      "Epoch 29 | Batch 60 | Loss: 0.0004\n",
      "Epoch 29 | Batch 70 | Loss: 0.0005\n",
      "Epoch 29 | Batch 80 | Loss: 0.1619\n",
      "Epoch 29 | Batch 90 | Loss: 0.0786\n",
      "Validation Loss: 2.3500 | Validation Accuracy: 0.5904\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch29_valacc0.5904_text.pth\n",
      "\n",
      "Epoch 30/30\n",
      "Epoch 30 | Batch 0 | Loss: 0.0005\n",
      "Epoch 30 | Batch 10 | Loss: 0.0006\n",
      "Epoch 30 | Batch 20 | Loss: 0.0003\n",
      "Epoch 30 | Batch 30 | Loss: 0.0003\n",
      "Epoch 30 | Batch 40 | Loss: 0.0002\n",
      "Epoch 30 | Batch 50 | Loss: 0.0003\n",
      "Epoch 30 | Batch 60 | Loss: 0.0004\n",
      "Epoch 30 | Batch 70 | Loss: 0.0003\n",
      "Epoch 30 | Batch 80 | Loss: 0.0005\n",
      "Epoch 30 | Batch 90 | Loss: 0.0002\n",
      "Validation Loss: 2.3643 | Validation Accuracy: 0.6024\n",
      "Model saved to C:/Users/Rifat/Music/Models/ver0o1\\BERT_epoch30_valacc0.6024_text.pth\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Initialize BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Training and validation\n",
    "epochs = 30\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1} | Batch {batch_idx} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            val_loss += outputs.loss.item()\n",
    "            \n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(F.softmax(logits, dim=1), dim=1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "    \n",
    "    val_accuracy = correct / len(val_dataset)\n",
    "    print(f\"Validation Loss: {val_loss / len(val_loader):.4f} | Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Save the model after each epoch\n",
    "    model_file_name = f\"BERT_epoch{epoch+1}_valacc{val_accuracy:.4f}_text.pth\"\n",
    "    model_save_path_epoch = os.path.join(model_save_path, model_file_name)\n",
    "    torch.save(model.state_dict(), model_save_path_epoch)\n",
    "    print(f\"Model saved to {model_save_path_epoch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1eb480-c0a1-4887-b7fd-9f10ad4e19ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224843eb-6144-4ba8-9ca2-adac965d2266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
